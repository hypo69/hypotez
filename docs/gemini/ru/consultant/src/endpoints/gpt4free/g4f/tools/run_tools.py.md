### **–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –º–æ–¥—É–ª—è `run_tools.py`**

## \file /hypotez/src/endpoints/gpt4free/g4f/tools/run_tools.py

–ú–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ, –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏ —Ä–∞–±–æ—Ç–∞ —Å —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º bucket.

**–ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞**:
- **–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º**: 7/10
- **–ü–ª—é—Å—ã**:
  - –ö–æ–¥ —Ä–∞–∑–±–∏—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –∏ –∫–ª–∞—Å—Å—ã, —á—Ç–æ –æ–±–ª–µ–≥—á–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É.
  - –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á.
  - –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π.
- **–ú–∏–Ω—É—Å—ã**:
  - –ù–µ –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º–µ—Ç–æ–¥—ã –∏–º–µ—é—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–µ docstring.
  - –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–µ—Å—Ç–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–º–µ—à–∞–Ω–Ω—ã–π —Å—Ç–∏–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, `asyncio.run` –≤–Ω—É—Ç—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏).
  - –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `logger` –∏–∑ `src.logger`.
  - –ù–µ –≤–µ–∑–¥–µ –µ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤.

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é**:

1.  **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞**:
    *   –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ docstring –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è —Ñ–æ—Ä–º–∞—Ç, —É–∫–∞–∑–∞–Ω–Ω—ã–π –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.
    *   –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ docstring –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ç—Ä–µ–±—É–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
2.  **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ**:
    *   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å `logger` –∏–∑ `src.logger` –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫ –∏ –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.
    *   –ó–∞–º–µ–Ω–∏—Ç—å `debug.error` –Ω–∞ `logger.error`.
3.  **–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π**:
    *   –í–æ –≤—Å–µ—Ö –±–ª–æ–∫–∞—Ö `except` –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `ex` –≤–º–µ—Å—Ç–æ `e` –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è.
    *   –î–æ–±–∞–≤–∏—Ç—å `exc_info=True` –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—à–∏–±–æ–∫, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–∫–ª—é—á–µ–Ω–∏–∏.
4.  **–¢–∏–ø–∏–∑–∞—Ü–∏—è**:
    *   –î–æ–±–∞–≤–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π.
    *   –ó–∞–º–µ–Ω–∏—Ç—å `Union` –Ω–∞ `|` –≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è—Ö —Ç–∏–ø–æ–≤.
5.  **–°—Ç–∏–ª—å –∫–æ–¥–∞**:
    *   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –¥–ª—è —Å—Ç—Ä–æ–∫.
    *   –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è.
6.  **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å**:
    *   –ò–∑–±–µ–≥–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `asyncio.run` –≤–Ω—É—Ç—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
7.  **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**:
    *   –û–±—Ä–∞–±–æ—Ç–∫–∞ API –∫–ª—é—á–µ–π —Ç—Ä–µ–±—É–µ—Ç –æ—Å–æ–±–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è. –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–ª—é—á–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ö—Ä–∞–Ω—è—Ç—Å—è –∏ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è.
8. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ webdriver**
    *    –£—á–µ—Å—Ç—å webdriver –≤ –∫–æ–¥–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `driver.execute_locator(l:dict)`
       –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–±-—ç–ª–µ–º–µ–Ω—Ç–∞–º–∏.

**–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥**:

```python
from __future__ import annotations

import re
import json
import asyncio
import time
from pathlib import Path
from typing import Optional, Callable, AsyncIterator, Iterator, Dict, Any, Tuple, List
from src.logger import logger  # –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
from ..typing import Messages
from ..providers.helper import filter_none
from ..providers.asyncio import to_async_iterator
from ..providers.response import Reasoning, FinishReason, Sources
from ..providers.types import ProviderType
from ..cookies import get_cookies_dir
from .web_search import do_search, get_search_message
from .files import read_bucket, get_bucket_dir
#from .. import debug #–£–¥–∞–ª—è—é debug, —Ç.–∫. –Ω–∞–¥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å logger

# Constants
BUCKET_INSTRUCTIONS = """
Instruction: Make sure to add the sources of cites using [[domain]](Url) notation after the reference. Example: [[a-z0-9.]](http://example.com)
"""

TOOL_NAMES = {
    'SEARCH': 'search_tool',
    'CONTINUE': 'continue_tool',
    'BUCKET': 'bucket_tool'
}


class ToolHandler:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    ===================================================
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤,
    –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏ —Ä–∞–±–æ—Ç—ã —Å bucket.
    """

    @staticmethod
    def validate_arguments(data: dict) -> dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ —Ä–∞–∑–±–∏—Ä–∞–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.

        Args:
            data (dict): –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç—ã.

        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.

        Raises:
            ValueError: –ï—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º –∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–æ–π.
        """
        if 'arguments' in data:
            if isinstance(data['arguments'], str):
                data['arguments'] = json.loads(data['arguments'])
            if not isinstance(data['arguments'], dict):
                raise ValueError('Tool function arguments must be a dictionary or a json string')
            else:
                return filter_none(**data['arguments'])
        else:
            return {}

    @staticmethod
    async def process_search_tool(messages: Messages, tool: dict) -> Tuple[Messages, Optional[Sources]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞.

        Args:
            messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            tool (dict): –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ.

        Returns:
            Tuple[Messages, Optional[Sources]]: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        """
        messages = messages.copy()
        args = ToolHandler.validate_arguments(tool['function'])
        messages[-1]['content'], sources = await do_search(
            messages[-1]['content'],
            **args
        )
        return messages, sources

    @staticmethod
    def process_continue_tool(messages: Messages, tool: dict, provider: Any) -> Tuple[Messages, Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.

        Args:
            messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            tool (dict): –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ.
            provider (Any): –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞.

        Returns:
            Tuple[Messages, Dict[str, Any]]: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.
        """
        kwargs = {}
        if provider not in ('OpenaiAccount', 'HuggingFaceAPI'):
            messages = messages.copy()
            last_line = messages[-1]['content'].strip().splitlines()[-1]
            content = f'Carry on from this point:\\n{last_line}'
            messages.append({'role': 'user', 'content': content})
        else:
            # Enable provider native continue
            kwargs['action'] = 'continue'
        return messages, kwargs

    @staticmethod
    def process_bucket_tool(messages: Messages, tool: dict) -> Messages:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ bucket.

        Args:
            messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            tool (dict): –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ.

        Returns:
            Messages: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ bucket.
        """
        messages = messages.copy()

        def on_bucket(match: re.Match) -> str:
            """
            –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ bucket –ø–æ ID.

            Args:
                match (re.Match): –û–±—ä–µ–∫—Ç Match —Å–æ–¥–µ—Ä–∂–∞—â–∏–π ID bucket.

            Returns:
                str: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ bucket.
            """
            return ''.join(read_bucket(get_bucket_dir(match.group(1))))

        has_bucket = False
        for message in messages:
            if 'content' in message and isinstance(message['content'], str):
                new_message_content = re.sub(r'{"bucket_id":"([^"]*)"}', on_bucket, message['content'])
                if new_message_content != message['content']:
                    has_bucket = True
                    message['content'] = new_message_content

        last_message_content = messages[-1]['content']
        if has_bucket and isinstance(last_message_content, str):
            if '\\nSource: ' in last_message_content:
                messages[-1]['content'] = last_message_content + BUCKET_INSTRUCTIONS

        return messages

    @staticmethod
    async def process_tools(messages: Messages, tool_calls: List[dict], provider: Any) -> Tuple[Messages, Optional[Sources], Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ kwargs.

        Args:
            messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            tool_calls (List[dict]): –°–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
            provider (Any): –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤.

        Returns:
            Tuple[Messages, Optional[Sources], Dict[str, Any]]: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π, –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
        """
        if not tool_calls:
            return messages, None, {}

        extra_kwargs = {}
        messages = messages.copy()
        sources = None

        for tool in tool_calls:
            if tool.get('type') != 'function':
                continue

            function_name = tool.get('function', {}).get('name')

            if function_name == TOOL_NAMES['SEARCH']:
                messages, sources = await ToolHandler.process_search_tool(messages, tool)

            elif function_name == TOOL_NAMES['CONTINUE']:
                messages, kwargs = ToolHandler.process_continue_tool(messages, tool, provider)
                extra_kwargs.update(kwargs)

            elif function_name == TOOL_NAMES['BUCKET']:
                messages = ToolHandler.process_bucket_tool(messages, tool)

        return messages, sources, extra_kwargs


class AuthManager:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è API –∫–ª—é—á–∞–º–∏.
    ==================================

    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —Å API –∫–ª—é—á–æ–º –∏ –∑–∞–≥—Ä—É–∑–∫–∏ API –∫–ª—é—á–∞.
    """

    @staticmethod
    def get_api_key_file(cls: Any) -> Path:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å API –∫–ª—é—á–æ–º –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.

        Args:
            cls (Any): –ö–ª–∞—Å—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.

        Returns:
            Path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å API –∫–ª—é—á–æ–º.
        """
        return Path(get_cookies_dir()) / f'api_key_{cls.parent if hasattr(cls, "parent") else cls.__name__}.json'

    @staticmethod
    def load_api_key(provider: Any) -> Optional[str]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç API –∫–ª—é—á –∏–∑ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.

        Args:
            provider (Any): –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è API –∫–ª—é—á.

        Returns:
            Optional[str]: API –∫–ª—é—á –∏–ª–∏ None, –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.
        """
        if not getattr(provider, 'needs_auth', False):
            return None

        auth_file = AuthManager.get_api_key_file(provider)
        try:
            if auth_file.exists():
                with auth_file.open('r') as f:
                    auth_result = json.load(f)
                return auth_result.get('api_key')
        except (json.JSONDecodeError, PermissionError, FileNotFoundError) as ex: #–ü–æ–º–µ–Ω—è–ª e –Ω–∞ ex
            logger.error(f'Failed to load API key: {ex.__class__.__name__}: {ex}', exc_info=True) #–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª logger –≤–º–µ—Å—Ç–æ debug
        return None


class ThinkingProcessor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–æ–≤ "thinking".
    =======================================

    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –º—ã—à–ª–µ–Ω–∏—è.
    """

    @staticmethod
    def process_thinking_chunk(chunk: str, start_time: float = 0) -> Tuple[float, List[Reasoning | str]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞–Ω–∫ "thinking" –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

        Args:
            chunk (str): –ß–∞–Ω–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            start_time (float, optional): –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –º—ã—à–ª–µ–Ω–∏—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.

        Returns:
            Tuple[float, List[Reasoning | str]]: –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏ —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        """
        results: List[Reasoning | str] = []

        # Handle non-thinking chunk
        if not start_time and '<think>' not in chunk and '</think>' not in chunk:
            return 0, [chunk]

        # Handle thinking start
        if '<think>' in chunk and '`<think>`' not in chunk:
            before_think, *after = chunk.split('<think>', 1)

            if before_think:
                results.append(before_think)

            results.append(Reasoning(status='ü§î Is thinking...', is_thinking='<think>'))

            if after:
                if '</think>' in after[0]:
                    after, *after_end = after[0].split('</think>', 1)
                    results.append(Reasoning(after))
                    results.append(Reasoning(status='Finished', is_thinking='</think>'))
                    if after_end:
                        results.append(after_end[0])
                    return 0, results
                else:
                    results.append(Reasoning(after[0]))

            return time.time(), results

        # Handle thinking end
        if '</think>' in chunk:
            before_end, *after = chunk.split('</think>', 1)

            if before_end:
                results.append(Reasoning(before_end))

            thinking_duration = time.time() - start_time if start_time > 0 else 0

            status = f'Thought for {thinking_duration:.2f}s' if thinking_duration > 1 else 'Finished'
            results.append(Reasoning(status=status, is_thinking='</think>'))

            # Make sure to handle text after the closing tag
            if after and after[0].strip():
                results.append(after[0])

            return 0, results

        # Handle ongoing thinking
        if start_time:
            return start_time, [Reasoning(chunk)]

        return start_time, [chunk]


async def perform_web_search(messages: Messages, web_search_param: Any) -> Tuple[Messages, Optional[Sources]]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.

    Args:
        messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        web_search_param (Any): –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞.

    Returns:
        Tuple[Messages, Optional[Sources]]: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
    """
    messages = messages.copy()
    sources = None

    if not web_search_param:
        return messages, sources

    try:
        search_query = web_search_param if isinstance(web_search_param, str) and web_search_param != 'true' else None
        messages[-1]['content'], sources = await do_search(messages[-1]['content'], search_query)
    except Exception as ex: #–ü–æ–º–µ–Ω—è–ª e –Ω–∞ ex
        logger.error(f'Couldn\'t do web search: {ex.__class__.__name__}: {ex}', exc_info=True) #–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª logger –≤–º–µ—Å—Ç–æ debug

    return messages, sources


async def async_iter_run_tools(
    provider: ProviderType,
    model: str,
    messages: Messages,
    tool_calls: Optional[List[dict]] = None,
    **kwargs
) -> AsyncIterator:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

    Args:
        provider (ProviderType): –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤.
        model (str): –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
        messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        tool_calls (Optional[List[dict]], optional): –°–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None.
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.

    Yields:
        AsyncIterator: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    """
    # Process web search
    sources = None
    web_search = kwargs.get('web_search')
    if web_search:
        messages, sources = await perform_web_search(messages, web_search)

    # Get API key if needed
    api_key = AuthManager.load_api_key(provider)
    if api_key and 'api_key' not in kwargs:
        kwargs['api_key'] = api_key

    # Process tool calls
    if tool_calls:
        messages, sources, extra_kwargs = await ToolHandler.process_tools(messages, tool_calls, provider)
        kwargs.update(extra_kwargs)

    # Generate response
    create_function = provider.get_async_create_function()
    response = to_async_iterator(create_function(model=model, messages=messages, **kwargs))

    async for chunk in response:
        yield chunk

    # Yield sources if available
    if sources:
        yield sources


def iter_run_tools(
    iter_callback: Callable,
    model: str,
    messages: Messages,
    provider: Optional[str] = None,
    tool_calls: Optional[List[dict]] = None,
    **kwargs
) -> Iterator:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

    Args:
        iter_callback (Callable): –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º.
        model (str): –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
        messages (Messages): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        provider (Optional[str], optional): –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None.
        tool_calls (Optional[List[dict]], optional): –°–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None.
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.

    Yields:
        Iterator: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    """
    # Process web search
    web_search = kwargs.get('web_search')
    sources = None

    if web_search:
        try:
            messages = messages.copy()
            search_query = web_search if isinstance(web_search, str) and web_search != 'true' else None
            # Note: Using asyncio.run inside sync function is not ideal, but maintaining original pattern
            messages[-1]['content'], sources = asyncio.run(do_search(messages[-1]['content'], search_query))
        except Exception as ex: #–ü–æ–º–µ–Ω—è–ª e –Ω–∞ ex
            logger.error(f'Couldn\'t do web search: {ex.__class__.__name__}: {ex}', exc_info=True) #–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª logger –≤–º–µ—Å—Ç–æ debug

    # Get API key if needed
    if provider is not None and getattr(provider, 'needs_auth', False) and 'api_key' not in kwargs:
        api_key = AuthManager.load_api_key(provider)
        if api_key:
            kwargs['api_key'] = api_key

    # Process tool calls
    if tool_calls:
        for tool in tool_calls:
            if tool.get('type') == 'function':
                function_name = tool.get('function', {}).get('name')

                if function_name == TOOL_NAMES['SEARCH']:
                    tool['function']['arguments'] = ToolHandler.validate_arguments(tool['function'])
                    messages[-1]['content'] = get_search_message(
                        messages[-1]['content'],
                        raise_search_exceptions=True,
                        **tool['function']['arguments']
                    )
                elif function_name == TOOL_NAMES['CONTINUE']:
                    if provider not in ('OpenaiAccount', 'HuggingFace'):
                        last_line = messages[-1]['content'].strip().splitlines()[-1]
                        content = f'Carry on from this point:\\n{last_line}'
                        messages.append({'role': 'user', 'content': content})
                    else:
                        # Enable provider native continue
                        kwargs['action'] = 'continue'
                elif function_name == TOOL_NAMES['BUCKET']:
                    def on_bucket(match: re.Match) -> str:
                        return ''.join(read_bucket(get_bucket_dir(match.group(1))))
                    has_bucket = False
                    for message in messages:
                        if 'content' in message and isinstance(message['content'], str):
                            new_message_content = re.sub(r'{"bucket_id":"([^"]*)"}', on_bucket, message['content'])
                            if new_message_content != message['content']:
                                has_bucket = True
                                message['content'] = new_message_content
                    last_message = messages[-1]['content']
                    if has_bucket and isinstance(last_message, str):
                        if '\\nSource: ' in last_message:
                            messages[-1]['content'] = last_message + BUCKET_INSTRUCTIONS

    # Process response chunks
    thinking_start_time = 0
    processor = ThinkingProcessor()

    for chunk in iter_callback(model=model, messages=messages, provider=provider, **kwargs):
        if isinstance(chunk, FinishReason):
            if sources is not None:
                yield sources
                sources = None
            yield chunk
            continue
        elif isinstance(chunk, Sources):
            sources = None
        if not isinstance(chunk, str):
            yield chunk
            continue

        thinking_start_time, results = processor.process_thinking_chunk(chunk, thinking_start_time)

        for result in results:
            yield result

    if sources is not None:
        yield sources