{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00175c6-7235-4abf-9c0d-a131b6d170b0",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file src/webdriver/llm_driver/simple_browser.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM —á–µ—Ä–µ–∑ LangChain –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤. –ö–ª—é—á - `emil`\n",
    "==================================================================================\n",
    "(–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ —Å BrowserController –∏/–∏–ª–∏ API –ø–æ–∏—Å–∫–∞)\n",
    "\n",
    "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è:\n",
    "- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (Gemini, OpenAI).\n",
    "- –£—Å—Ç–∞–Ω–æ–≤–∫–∏ API –∫–ª—é—á–µ–π.\n",
    "- –ó–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–≤–µ–±-–ø–æ–∏—Å–∫, –±—Ä–∞—É–∑–µ—Ä).\n",
    "- –í—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –¥–æ –∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (`run_task`).\n",
    "- –°—Ç—Ä–∏–º–∏–Ω–≥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ (`stream_task`).\n",
    "\n",
    "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:\n",
    "    - langchain-openai, langchain-google-genai, langchain-core, langchainhub, langchain\n",
    "    - langchain-community (–¥–ª—è SerpAPIWrapper)\n",
    "    - google-search-results (–¥–ª—è SerpAPIWrapper)\n",
    "    - python-dotenv\n",
    "    - browser_use (–∏–ª–∏ –≤–∞—à –º–æ–¥—É–ª—å —Å BrowserController)\n",
    "    - src.gs, src.logger, src.utils, header\n",
    "```rst\n",
    ".. module:: src.webdriver.llm_driver.simple_browser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922ec09d-83d7-460b-9487-a15b5a3bf586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [browser_use] BrowserUse logging setup complete with level info\n",
      "INFO     [telemetry] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.\n",
      "INFO     [numexpr.utils] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO     [numexpr.utils] NumExpr defaulting to 8 threads.\n",
      "WARNING  [logger_console] ‚ö†Ô∏è \u001b[91m\u001b[49mError fetching data from git: https://api.github.com/repos/hypotez/hypo/releases/latest\n",
      " response.status_code=404 \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä—ã —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ src.webdriver.llm_driver.controllers. \u001b[0m\n",
      "WARNING  [logger_console] ‚ö†Ô∏è \u001b[91m\u001b[49m.env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: C:\\Users\\user\\Documents\\repos\\hypotez\\.env. \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ C:\\Users\\user\\Documents\\repos\\hypotez\\src\\webdriver\\llm_driver\\use_llm.json \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mConfig Gemini: Status=active, Model=gemini-2.5-flash-preview-04-17, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mConfig OpenAI: Status=disabled, Model=gpt-4o, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mConfig SerpAPI: Status=inactive, Key Present=True \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mConfig DuckDuckGo: Status=active \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mConfig Tavily: Status=inactive, Key Present=False \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipdb # <- —Ç—Ä–∞—Å–∏—Ä–æ–≤–∫–∞ –∏ —Ç–æ—á–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∞\n",
    "import os\n",
    "import asyncio\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Dict, Any, Optional, Callable, Type, Tuple, AsyncIterator\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.exceptions import LangChainException\n",
    "from langchain import hub\n",
    "# --- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ API ---\n",
    "# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: pip install google-search-results\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from browser_use import Agent\n",
    "\n",
    "# --- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–æ–¥—É–ª–∏ ---\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "# from src.webdriver.ai_browser import tools\n",
    "# from src.webdriver.ai_browser.tools import get_tools, get_tools_by_type, get_tools_by_name\n",
    "from src.webdriver.llm_driver.use_llm import Config, Driver, stream_agent_execution\n",
    "\n",
    "from src.logger import logger\n",
    "from src.utils.jjson import j_loads, j_loads_ns\n",
    "from src.utils.printer import pprint as print\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6800e6-1d41-415f-9845-8925c5f48f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT:Path = Path(__root__/'SANDBOX'/'davidka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304c99e5-9452-4fc7-8b4e-669dd093951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDriver(Driver):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, \n",
    "                 GEMINI_API_KEY:str = None, \n",
    "                 OPENAI_API_KEY:str = None, \n",
    "                 openai_model_name:str = None, \n",
    "                 gemini_model_name:str = None, \n",
    "                 start_browser:str = True,\n",
    "                **kwargs):\n",
    "        super().__init__(GEMINI_API_KEY, OPENAI_API_KEY, openai_model_name, gemini_model_name, start_browser, **kwargs) \n",
    "\n",
    "    async def simple_process_task_async(self, task:str = 'Hello, world!') -> Any:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        result_dict:dict = {}\n",
    "\n",
    "        def clean_json(raw_text: str) -> str:\n",
    "            # 1. –£–±–∏—Ä–∞–µ–º –≤—Å—ë –¥–æ –ø–µ—Ä–≤–æ–π —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–∏ {\n",
    "\n",
    "            json_start = raw_text.find('{')\n",
    "            if json_start == -1:\n",
    "                return raw_text  # –Ω–µ—Ç —Å–∫–æ–±–∫–∏, –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–π —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–∏\n",
    "            json_cleaned = raw_text[json_start:]\n",
    "    \n",
    "            # 2. –£–±–∏—Ä–∞–µ–º –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ —Ç—Ä–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏–ª–∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã\n",
    "            json_cleaned = json_cleaned.strip('`\\n ')\n",
    "            \n",
    "            return json_cleaned\n",
    "\n",
    "        try:\n",
    "            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ —Å —Å–ø–∏—Å–∫–æ–º –º–æ–¥–µ–ª–µ–π –∏ –∑–∞–¥–∞—á–µ–π\n",
    "            # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –∫–ª–∞—Å—Å Agent –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Å–ø–∏—Å–æ–∫ LLM –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ 'llm'\n",
    "            agent = Agent(\n",
    "                task=task,\n",
    "                llm=self.gemini, # –ü–µ—Ä–µ–¥–∞—á–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ωo–π –º–æ–¥–µ–ª–∏\n",
    "                # –î—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Agent, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å\n",
    "            )\n",
    "            logger.info(f\"–ê–≥–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: \\\"{task}\\\"\")\n",
    "            answer: Any = await agent.run() # –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞\n",
    "            if not answer:\n",
    "                logger.error('–ù–µ –≤–µ—Ä–Ω—É–ª—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞')\n",
    "                ...\n",
    "            timestamp:str = gs.now\n",
    "\n",
    "            for action_result in answer.history:\n",
    "                result_list:list = getattr(action_result, 'result', None)\n",
    "                result:'ActionResult' = result_list[0]\n",
    "                extracted_content:str =\tresult.extracted_content\n",
    "\n",
    "                cleaned_json_text = clean_json(extracted_content)\n",
    "                try:\n",
    "                    data = j_loads(cleaned_json_text)  # –ó–∞–≥—Ä—É–∂–∞–µ–º JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞\n",
    "                    if not data: continue\n",
    "                except Exception as ex:\n",
    "                    logger.error(\"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON\", ex, exc_info=True)\n",
    "                    ...\n",
    "                    continue\n",
    "\n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "                timestamp = gs.now\n",
    "                j_dumps(data, Config.ENDPOINT/'train_data_products'/f'product_links_{timestamp}.json')\n",
    "                result_dict.update(data)\n",
    "\n",
    "            logger.info(\"–ê–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏.\")\n",
    "            ...\n",
    "            return result_dict \n",
    "        except Exception as agent_err:\n",
    "            logger.error(f\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–º./n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n\", agent_err, exc_info=True)\n",
    "            ...\n",
    "            return '' # –í–æ–∑–≤—Ä–∞—Ç None –ø—Ä–∏ –æ—à–∏–±–∫–µ –∞–≥–µ–Ω—Ç–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79907a87-6334-4ccb-af83-7aa0447674b7",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file /sandbox/davidka/crawler_simple_driver.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ SimpleDriver\n",
    "=====================================================\n",
    "(–∞–¥–∞–ø—Ç–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ crawler.py)\n",
    "```rst\n",
    ".. module:: sandbox.davidka.crawler_simple_driver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c649b671-4a0d-47e3-ba42-b61c0a90023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "from src.webdriver.llm_driver.simple_driver import SimpleDriver\n",
    "from src.utils.jjson import j_loads, j_dumps\n",
    "from src.utils.file import read_text_file, save_text_file, get_filenames_from_directory\n",
    "from src.utils.url import get_domain\n",
    "from src.utils.string.ai_string_utils import normalize_answer\n",
    "from src.utils.printer import pprint as print\n",
    "from src.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f67341-1c7b-4b68-9487-31656768d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m--- –ù–∞—á–∞–ª–æ –°–ò–ù–•–†–û–ù–ù–û–ô –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Driver --- \u001b[0m\n",
      "WARNING  [logger_console] ‚ö†Ô∏è \u001b[91m\u001b[49mOpenAI LLM –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Key=True, Status=disabled, Model=True) \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini: Model=gemini-2.5-flash-preview-04-17 \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49mGemini LLM –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. \u001b[0m\n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m--- –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Driver –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ async_init() --- \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    ENDPOINT: Path = __root__ / 'SANDBOX' / 'davidka'\n",
    "    mining_data_path: Path = ENDPOINT / 'random_urls'\n",
    "    train_data_supplier_categories_path: Path = ENDPOINT / 'train_data_supplier_categories'\n",
    "    checked_domains: list = read_text_file(ENDPOINT / 'checked_domains.txt', as_list=True)\n",
    "    crawl_files_list: list = get_filenames_from_directory(mining_data_path, 'json')\n",
    "    instruction_grab_product_page_simple_driver: str = (ENDPOINT / 'instructions' / 'grab_product_page_simple_driver.md').read_text(encoding='utf-8')\n",
    "    instruction_get_supplier_categories: str = (ENDPOINT / 'instructions' / 'get_supplier_categories.md').read_text(encoding='utf-8')\n",
    "    instruction_find_product_in_supplier_domain: str = (ENDPOINT / 'instructions' / 'find_product_in_supplier_domain.md').read_text(encoding='utf-8')\n",
    "    instruction_for_products_urls_one_product: str = (ENDPOINT / 'instructions' / 'get_product_links_one_product.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_search: str = (ENDPOINT / 'instructions' / 'links_from_search.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_searh_page: str = (ENDPOINT / 'instructions' / 'links_from_searh_page.md').read_text(encoding='utf-8')\n",
    "    GEMINI_API_KEY = gs.credentials.gemini.emil.api_key\n",
    "    driver: SimpleDriver = SimpleDriver(gemini_model_name='gemini-1.5-flash-8b-exp-0924', GEMINI_API_KEY = GEMINI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fb6b00-8db1-49cc-b60c-f7f70ab7dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_urls_list_from_files(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª—ã —Å –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç product_url —Å–ø–∏—Å–∫–æ–º\"\"\"\n",
    "    products_urls_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                products_urls_list.append(product['product_url'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename=}', ex, exc_info=True)\n",
    "    random.shuffle(products_urls_list)\n",
    "    return products_urls_list\n",
    "\n",
    "\n",
    "def yield_product_urls_from_files(directory: Path = Config.mining_data_path, pattern: str = 'json'):\n",
    "    \"\"\"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä url –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤\"\"\"\n",
    "    filenames = get_filenames_from_directory(directory, pattern)\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            file_path = directory / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                yield product['product_url']\n",
    "        except Exception as ex:\n",
    "            logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename=}', ex, exc_info=True)\n",
    "\n",
    "\n",
    "def get_categories_from_random_urls(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤\"\"\"\n",
    "    categories_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                if 'parent_category' in product:\n",
    "                    categories_list.append(product['parent_category'])\n",
    "                if 'category_name' in product:\n",
    "                    categories_list.append(product['category_name'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename=}', ex, exc_info=True)\n",
    "    categories_list = list(filter(None, set(categories_list)))\n",
    "    random.shuffle(categories_list)\n",
    "    return categories_list\n",
    "\n",
    "\n",
    "async def get_products_urls(category: str, task:str = '', num_of_links: str = '10') -> str:\n",
    "    \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\"\"\"\n",
    "    try:\n",
    "        driver = Config.driver\n",
    "        logger.info(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {category=}')\n",
    "        \n",
    "        task = task or Config.instruction_links_from_searh_page.replace('{PRODUCT_CATEGORY}', category).replace('{NUM_LINKS}', num_of_links)\n",
    "        #ipdb.set_trace()\n",
    "        answer = await driver.simple_process_task_async(task)\n",
    "        if not answer:\n",
    "            return ''\n",
    "        print('\\n -------------------------------- EXTRACTED DATA \\n------------------------------------------\\n')\n",
    "        print(answer)\n",
    "        print('\\n -------------------------------------------------------------------------------------------')\n",
    "        return answer\n",
    "    except Exception as ex:\n",
    "        logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {category=}', ex, exc_info=True)\n",
    "        return ''\n",
    "\n",
    "\n",
    "async def fetch_categories_from_suppliers_random_urls() -> dict:\n",
    "    \"\"\"–°–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å —Å–∞–π—Ç–æ–≤\"\"\"\n",
    "    categories_dict = {}\n",
    "    driver = Config.driver\n",
    "\n",
    "    for filename in Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                domain = get_domain(product['product_url'])\n",
    "                if domain in Config.checked_domains:\n",
    "                    continue\n",
    "                task = Config.instruction_get_supplier_categories.replace('{INPUT_URL}', domain)\n",
    "                res = await driver.simple_process_task_async(task)\n",
    "                if not res:\n",
    "                    continue\n",
    "                normalized_res = normalize_answer(res.get('output', ''))\n",
    "                data = j_loads(normalized_res)\n",
    "                print(data)\n",
    "                j_dumps(data, Config.train_data_supplier_categories_path / f'{gs.now}.json')\n",
    "                Config.checked_domains.append(domain)\n",
    "                save_text_file(Config.checked_domains, Config.ENDPOINT / 'checked_domains.txt')\n",
    "                j_dumps(Config.checked_domains, Config.ENDPOINT / 'checked_domains.json')\n",
    "        except Exception as ex:\n",
    "            logger.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename=}', ex, exc_info=True)\n",
    "    return categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9568bd-ee6c-4a51-9c1b-d6248b82428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m–û–±—Ä–∞–±–æ—Ç–∫–∞ category='Temperature Controllers' \u001b[0m\n",
      "INFO     [agent] üß† Starting an agent with main_model=models/gemini-2.5-flash-preview-04-17 +vision, planner_model=None, extraction_model=None \n",
      "INFO     [logger_console] ‚ÑπÔ∏è \u001b[32m\u001b[49m–ê–≥–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: \"\n",
      "```md\n",
      "**–†–æ–ª—å:** –¢—ã ‚Äî –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –í–µ–±-–ê–≥–µ–Ω—Ç –¥–ª—è –ü–æ–∏—Å–∫–∞ –°—Ç—Ä–∞–Ω–∏—Ü.\n",
      "\n",
      "**–¶–µ–ª—å:**  \n",
      "–ù–∞–π—Ç–∏ **–≤—Å–µ —Å—Å—ã–ª–∫–∏** –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É `Temperature Controllers`.\n",
      "\n",
      "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n",
      "\n",
      "1. **–û—Ç–∫—Ä–æ–π –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É** (–Ω–∞–ø—Ä–∏–º–µ—Ä, Google, Bing –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é).\n",
      "\n",
      "2. \n",
      "- **–í–≤–µ–¥–∏ –∑–∞–ø—Ä–æ—Å**: `Temperature Controllers`.\n",
      "\n",
      "3. **–ò–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞**:\n",
      "\n",
      "   - –°–æ–±–µ—Ä–∏ **–≤—Å–µ —Å—Å—ã–ª–∫–∏** –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞.\n",
      "   - –ü—Ä–æ–ø—É—Å–∫–∞–π —Ä–µ–∫–ª–∞–º–Ω—ã–µ –∏ —Å–ø–æ–Ω—Å–æ—Ä—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
      "   - –ü—Ä–æ–ø—É—Å–∫–∞–π —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ –∏ –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–∏.\n",
      "\n",
      "4. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫**:\n",
      "   - –ò–≥–Ω–æ—Ä–∏—Ä—É–π –≤—Å–µ —Å—Å—ã–ª–∫–∏, –≤ –¥–æ–º–µ–Ω–µ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:\n",
      "     - `youtube`\n",
      "     - `tiktok`\n",
      "     - `facebook`\n",
      "     - `instagram`\n",
      "     - `twitter`\n",
      "     - `linkedin`\n",
      "     - `pinterest`\n",
      "     - `vk`\n",
      "     - `reddit`\n",
      "     - `snapchat`\n",
      "     - –∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∏–ª–∏ –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–æ–≤.\n",
      "   - –ü—Ä–æ–≤–µ—Ä–∫—É –≤—ã–ø–æ–ª–Ω—è–π –ø–æ —á–∞—Å—Ç–∏ URL (–ø–æ–¥–¥–æ–º–µ–Ω –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–æ–º–µ–Ω).\n",
      "   - –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ —ç—Ç–∏—Ö —Å–ª–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–π –µ–≥–æ.\n",
      "\n",
      "5. **–ë–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–π**:\n",
      "   - –ù–µ –ø–µ—Ä–µ—Ö–æ–¥–∏ –ø–æ —Å—Å—ã–ª–∫–∞–º.\n",
      "   - –ù–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü.\n",
      "   - –¢–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω–∏ —Å–∞–º–∏ URL.\n",
      "\n",
      "---\n",
      "\n",
      "**üì¶ –§–æ—Ä–º–∞—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"links\": [\n",
      "    \"<—Å—Å—ã–ª–∫–∞ 1>\",\n",
      "    \"<—Å—Å—ã–ª–∫–∞ 2>\",\n",
      "    \"<—Å—Å—ã–ª–∫–∞ 3>\",\n",
      "    \"...\",\n",
      "    \"<–ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Å—ã–ª–∫–∞>\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**‚ö° –í–∞–∂–Ω–æ:**\n",
      "- –°–æ—Ö—Ä–∞–Ω—è–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞.\n",
      "- –ü—Ä–æ–ø—É—Å–∫–∞–π —Ä–µ–∫–ª–∞–º–Ω—ã–µ –∏ —Å–ø–æ–Ω—Å–æ—Ä—Å–∫–∏–µ –±–ª–æ–∫–∏.\n",
      "- –ü—Ä–æ–ø—É—Å–∫–∞–π —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ –∏ –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–∏.\n",
      "- –ù–∏–∫–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π ‚Äî —Ç–æ–ª—å–∫–æ JSON-–æ—Ç–≤–µ—Ç.\n",
      "```\n",
      "\" \u001b[0m\n",
      "WARNING  [langchain_google_genai.chat_models] Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 500\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "].\n",
      "ERROR    [agent] \n",
      "\n",
      "‚ùå  LLM ChatGoogleGenerativeAI connection test failed. Check that GEMINI_API_KEY is set correctly in .env and that the LLM API account has sufficient funding.\n",
      "\n",
      "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 500\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "\n",
      "ERROR    [logger_console] ‚ùå \u001b[31m\u001b[49m\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–º./n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n Failed to connect to LLM API or LLM API is not responding correctly\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Documents\\repos\\hypotez\\src\\webdriver\\llm_driver\\simple_driver.py\", line 112, in simple_process_task_async\n",
      "    answer = await agent.run()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\browser_use\\utils.py\", line 300, in wrapper\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\browser_use\\agent\\service.py\", line 793, in run\n",
      "    assert self.llm._verified_api_keys or SKIP_LLM_API_KEY_VERIFICATION, (\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Failed to connect to LLM API or LLM API is not responding correctly\n"
     ]
    }
   ],
   "source": [
    "driver = Config.driver\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n",
    "for category in get_categories_from_random_urls():\n",
    "    #ipdb.set_trace()\n",
    "    if not await get_products_urls(category = category, num_of_links = '10'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28ed5-5f08-4a92-8282-949542be9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
