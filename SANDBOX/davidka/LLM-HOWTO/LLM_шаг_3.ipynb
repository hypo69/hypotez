{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hypo69/hypotez/blob/master/SANDBOX/davidka/LLM-HOWTO/LLM_%D1%88%D0%B0%D0%B3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lIYdn1woOS1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "baa3d065-88d7-49bc-cdc6-6861c6e5931c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch accelerate huggingface_hub  #--quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "6xKeyir3r25U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка модели и данных\n",
        "\n",
        "Для текстовой классификации я выбрал модель *distilbert-base-uncased*"
      ],
      "metadata": {
        "id": "rgj1Qqb0XXVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Модель `\"distilbert-base-uncased\"`\n",
        "\n",
        "— облегчённая (дистиллированная) версия BERT. Название по частям:\n",
        "\n",
        " **1. `distilbert`**  \n",
        "- Это **дистиллированная (сжатая) версия BERT**.  \n",
        "- Обучена методом **knowledge distillation** (перенос знаний из большой модели `bert-base-uncased` в меньшую).  \n",
        "- Сохраняет ~95% качества оригинального BERT, но **в 2 раза быстрее** и **на 40% меньше** по размеру.\n",
        "\n",
        " **2. `base`**  \n",
        "- Размер модели: **\"base\"** (12 слоёв, 768 скрытых размерностей, 110 млн параметров).  \n",
        "- Есть также `tiny`, `mini`, `small` для ещё более лёгких экспериментов.\n",
        "\n",
        " **3. `uncased`**  \n",
        "- Модель **не различает регистр букв** (все тексты приводятся к нижнему регистру перед обработкой).  \n",
        "- Например: `\"Hello\"` и `\"hello\"` будут считаться одинаковыми.  \n",
        "- Если регистр важен (например, для именованных сущностей), следует изпользовать **`cased`**-версии.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Когда её использовать?**  \n",
        "- Для задач **классификации текста**, **NER**, **вопросо-ответных систем**.  \n",
        "- Если нужно **экономить ресурсы** (Colab/ноутбук с ограниченным GPU).  \n",
        "- Для экспериментов перед переходом на большие модели (например, `bert-large`).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### **Альтернативы**  \n",
        "- **`bert-base-uncased`** — оригинальная BERT (медленнее, но точнее).  \n",
        "- **`distilroberta-base`** — дистиллированная версия RoBERTa.  \n",
        "- **`google/electra-small`** — лёгкая модель.  \n",
        "\n",
        "Если нужна **модель для русского языка**, 👇  \n",
        "- `\"DeepPavlov/rubert-base-cased\"`  \n",
        "- `\"cointegrated/rubert-tiny2\"` (очень лёгкая).  \n"
      ],
      "metadata": {
        "id": "06GAc00wqjA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive и пути"
      ],
      "metadata": {
        "id": "0D7dYA4ZWGzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZPfFftZ4mM9",
        "outputId": "8d679d9b-15c8-4b59-8a61-cbd740dc46a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Пути\n",
        "storage:str = '/content/drive/MyDrive/hypo69/llm'\n",
        "train_data_path:str = f'{storage}/train_data'\n",
        "log_path:str = f'{storage}/logs'\n",
        "results_path:str = f'{storage}/results'\n",
        "checkpoints_path:str = f'{storage}/checkpoints'\n",
        "\n",
        "# Список файлов для тренировки\n",
        "json_train_files_list:list | str = glob.glob(os.path.join(train_data_path, '*.json'))\n",
        "json_train_files_list:list = json_train_files_list if isinstance(json_train_files_list, list) else [json_train_files_list]\n",
        "\n"
      ],
      "metadata": {
        "id": "dWB8ERDcYmXc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CSV"
      ],
      "metadata": {
        "id": "EWjetUEEQzPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#df = pd.read_csv('/content/drive/MyDrive/hypo69/llam_20250516T064847-195.csv')\n",
        "#dataset = Dataset.from_pandas(df)\n",
        "\n",
        "#train_df = pd.read_csv(\"train.csv\")\n",
        "#eval_df = pd.read_csv(\"val.csv\")\n",
        "\n",
        "#train_dataset = Dataset.from_pandas(train_df)\n",
        "#eval_dataset = Dataset.from_pandas(eval_df)"
      ],
      "metadata": {
        "id": "YAKEyvSDr9jd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JSON"
      ],
      "metadata": {
        "id": "rvkBRBCpQ6n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "records:list = []\n",
        "for file_path in json_train_files_list:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "\n",
        "            # Если это список словарей\n",
        "            if isinstance(data, list):\n",
        "                records.extend(data)\n",
        "            # Если это одиночный словарь\n",
        "            elif isinstance(data, dict):\n",
        "                records.append(data)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Ошибка при загрузке {file_path}: {e}')\n",
        "\n",
        "labels_dict: dict = {}\n",
        "try:\n",
        "    with open(f'{storage}/labels.json', 'r', encoding='utf-8') as f:\n",
        "        labels_dict = json.load(f)\n",
        "except Exception as e:\n",
        "    print"
      ],
      "metadata": {
        "id": "UG0hZZ7xQ9w9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(records)\n",
        "# Удаление строк с пустыми значениями в столбце 'text'\n",
        "df_cleaned = df.dropna(subset=['text'])  # Удаляет None/NaN\n",
        "df_cleaned = df_cleaned[df_cleaned['text'].astype(str).str.strip() != \"\"]  # Удаляет пустые строки\n",
        "print(f\"Было строк: {len(df)}, стало: {len(df_cleaned)}\")\n",
        "print(\"Примеры оставшихся текстов:\")\n",
        "print(df_cleaned['text'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU9okl2PE4i8",
        "outputId": "80f95ebf-da1a-4063-a0f1-579bbea1f470"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Было строк: 52, стало: 52\n",
            "Примеры оставшихся текстов:\n",
            "0    <div class=\"main-page-wrapper\"> <div class=\"cl...\n",
            "1    <div class=\"main-page-wrapper\"> <div class=\"cl...\n",
            "2    <div class=\"main-page-wrapper\"> <div class=\"cl...\n",
            "3    <div class=\"main-page-wrapper\"> <div class=\"cl...\n",
            "4    <div class=\"main-page-wrapper\"> <div class=\"cl...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset:Dataset = Dataset.from_pandas(df_cleaned)\n",
        "dataset = dataset.train_test_split(test_size=0.2)  # 80% train, 20% eval\n",
        "train_dataset:Dataset = dataset[\"train\"]\n",
        "eval_dataset:Dataset = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "cTMzq3--zS6p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Процесс обучения"
      ],
      "metadata": {
        "id": "S3PmIEnzze4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель ожидает последовательности фиксированной длины (512 токенов)\n",
        "\n",
        "Если данные содержат слишком длинные тексты (461 токен вместо ожидаемых 41)\n",
        "\n",
        "Проблема возникает при попытке создать батчи из разрозненных по длине последовательностей"
      ],
      "metadata": {
        "id": "iaEeoA0_GIpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Модуль для создания и обучения пайплайна классификации текста.\n",
        "================================================================\n",
        "Модуль определяет класс TextClassificationPipeline, который инкапсулирует\n",
        "логику токенизации, подготовки датасетов и обучения модели.\n",
        "Зависимости:\n",
        "    - transformers\n",
        "    - datasets\n",
        "    - torch\n",
        "    - numpy\n",
        "    - pandas\n",
        "    - huggingface_hub (для загрузки на Hub)\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Tuple, Any, Optional\n",
        "from pathlib import Path # Импортируем Path для работы с путями\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.trainer_utils import EvalPrediction\n",
        "from datasets import DatasetDict, Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "class TextClassificationPipeline:\n",
        "    \"\"\"\n",
        "    Пайплайн для классификации текста.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 model_name: str = 'distilbert-base-uncased',\n",
        "                 num_labels: int = 40,\n",
        "                 hub_model_id: Optional[str] = None,\n",
        "                 checkpoints_path: str = './results',\n",
        "                 labels_map_dict: Optional[Dict[str, int]] = None):\n",
        "\n",
        "        \"\"\"\n",
        "        Инициализация пайплайна.\n",
        "\n",
        "        Args:\n",
        "            model_name (str, optional): Имя или путь к предварительно обученной модели.\n",
        "            num_labels (int, optional): Количество меток для классификации.\n",
        "            hub_model_id (Optional[str], optional): ID модели на Hugging Face Hub.\n",
        "            checkpoints_path (str, optional): Путь к директории для сохранения чекпоинтов.\n",
        "                                              По умолчанию './results'.\n",
        "        \"\"\"\n",
        "        self.tokenizer: AutoTokenizer\n",
        "        self.model: AutoModelForSequenceClassification\n",
        "        self.num_labels: int\n",
        "        self.hub_model_id: Optional[str] = hub_model_id\n",
        "        self.checkpoints_path: str = checkpoints_path # Сохраняем путь для чекпоинтов\n",
        "\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                model_name,\n",
        "                num_labels=num_labels,\n",
        "                problem_type='single_label_classification'\n",
        "            )\n",
        "            self.num_labels = num_labels\n",
        "        except OSError as ex:\n",
        "            print(f\"Не удалось загрузить модель или токенизатор: {model_name}\\nException: {ex}\")\n",
        "            raise\n",
        "        except Exception as ex:\n",
        "            print(f\"Непредвиденная ошибка при инициализации TextClassificationPipeline: {model_name}\\nException: {ex}\")\n",
        "            raise\n",
        "\n",
        "    def tokenize(self,\n",
        "                 input_data: Dict[str, Any],\n",
        "                 max_length: int = 512,\n",
        "                 stride_ratio: float = 0.5) -> BatchEncoding:\n",
        "        \"\"\"\n",
        "        Токенизация текстовых данных с перекрытием (внахлест).\n",
        "        # ... (остальное описание Args и Returns) ...\n",
        "        \"\"\"\n",
        "        tokenized: BatchEncoding\n",
        "\n",
        "        actual_stride = min(max(0, int(max_length * stride_ratio)), max_length -1)\n",
        "        if actual_stride <= 0 and max_length > 0 :\n",
        "            if stride_ratio > 0 :\n",
        "                 print(f\"Предупреждение: stride_ratio > 0, но max_length ({max_length}) слишком мал. Stride установлен в 1.\")\n",
        "                 actual_stride = 1\n",
        "            else:\n",
        "                 actual_stride = 0\n",
        "\n",
        "        print(f\"Токенизация с max_length={max_length}, stride={actual_stride} (stride_ratio={stride_ratio})\")\n",
        "\n",
        "        tokenized = self.tokenizer(\n",
        "            input_data['text'],\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            stride=actual_stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        if 'labels' in input_data and 'overflow_to_sample_mapping' in tokenized:\n",
        "            original_labels = input_data['labels']\n",
        "            new_labels = []\n",
        "            for i in range(len(tokenized['input_ids'])):\n",
        "                original_sample_index = tokenized['overflow_to_sample_mapping'][i]\n",
        "                new_labels.append(original_labels[original_sample_index])\n",
        "            tokenized['labels'] = new_labels\n",
        "        elif 'labels' in input_data:\n",
        "            tokenized['labels'] = input_data['labels']\n",
        "\n",
        "        # ---- ИЗМЕНЕНИЕ ЗДЕСЬ ----\n",
        "        # Удаляем поле 'overflow_to_sample_mapping', так как оно больше не нужно\n",
        "        # и вызовет ошибку, если будет передано в модель.\n",
        "        if 'overflow_to_sample_mapping' in tokenized:\n",
        "            del tokenized['overflow_to_sample_mapping']\n",
        "        # Также, если ваш токенизатор добавляет 'offset_mapping' и он не нужен модели,\n",
        "        # его тоже можно удалить здесь, хотя обычно модели его игнорируют, если он не в их сигнатуре.\n",
        "        # if 'offset_mapping' in tokenized:\n",
        "        #     del tokenized['offset_mapping']\n",
        "        # --------------------------\n",
        "\n",
        "        return tokenized\n",
        "\n",
        "    def prepare_datasets(self, dataset_dict: DatasetDict) -> Tuple[Dataset, Dataset] | Tuple[None, None]:\n",
        "        \"\"\" Подготовка (токенизация) датасетов. \"\"\"\n",
        "        tokenized_datasets: DatasetDict\n",
        "        error_message: str\n",
        "\n",
        "        for split_name, current_dataset in dataset_dict.items():\n",
        "            if 'labels' not in current_dataset.column_names:\n",
        "                error_message = f\"Датасет '{split_name}' не содержит 'labels'. Колонки: {current_dataset.column_names}\"\n",
        "                print(error_message)\n",
        "                raise ValueError(error_message)\n",
        "            if 'text' not in current_dataset.column_names:\n",
        "                error_message = f\"Датасет '{split_name}' не содержит 'text'. Колонки: {current_dataset.column_names}\"\n",
        "                print(error_message)\n",
        "                raise ValueError(error_message)\n",
        "\n",
        "        try:\n",
        "            print(f\"Начало токенизации для датасетов: {list(dataset_dict.keys())}...\")\n",
        "            tokenized_datasets = dataset_dict.map(\n",
        "                self.tokenize,\n",
        "                batched=True,\n",
        "                remove_columns=['text']\n",
        "            )\n",
        "            print(\"Токенизация датасетов завершена.\")\n",
        "        except Exception as ex:\n",
        "            print(f\"Ошибка во время токенизации: {ex}\")\n",
        "            return None, None\n",
        "\n",
        "        if 'train' not in tokenized_datasets or 'test' not in tokenized_datasets:\n",
        "            print(f\"Ключи 'train' или 'test' отсутствуют. Ключи: {tokenized_datasets.keys()}\")\n",
        "            return None, None\n",
        "\n",
        "        return tokenized_datasets['train'], tokenized_datasets['test']\n",
        "\n",
        "    def train(self, train_dataset: Dataset, eval_dataset: Dataset) -> None:\n",
        "        \"\"\" Запуск процесса обучения модели. \"\"\"\n",
        "        training_args: TrainingArguments\n",
        "        trainer: Trainer\n",
        "\n",
        "        if not train_dataset:\n",
        "            print(\"Ошибка: Обучающий датасет пуст.\")\n",
        "            return\n",
        "\n",
        "        per_device_batch_size: int = 8\n",
        "        steps_per_epoch: int = math.ceil(len(train_dataset) / per_device_batch_size)\n",
        "        if steps_per_epoch == 0:\n",
        "            steps_per_epoch = 1\n",
        "        print(f\"Рассчитанное количество шагов на эпоху: {steps_per_epoch}\")\n",
        "\n",
        "        args_dict = {\n",
        "            'output_dir': self.checkpoints_path,\n",
        "            'per_device_train_batch_size': per_device_batch_size,\n",
        "            'per_device_eval_batch_size': 8,\n",
        "            'num_train_epochs': 3,\n",
        "            'do_eval': True,\n",
        "            'eval_steps': steps_per_epoch,\n",
        "            'logging_steps': steps_per_epoch,\n",
        "            'logging_first_step': True,\n",
        "            'save_steps': steps_per_epoch,\n",
        "            'remove_unused_columns': False,\n",
        "            # 'overwrite_output_dir': True, # Раскомментировать, для перезписи output_dir без ошибок\n",
        "        }\n",
        "\n",
        "        if self.hub_model_id:\n",
        "            args_dict['push_to_hub'] = True\n",
        "            args_dict['hub_model_id'] = self.hub_model_id\n",
        "            print(f\"Модель будет загружена на Hugging Face Hub как: {self.hub_model_id}\")\n",
        "            # Для управления частотой загрузки на Hub, если push_to_hub=True:\n",
        "            # args_dict['hub_strategy'] = \"every_save\" # Загружать при каждом сохранении чекпоинта\n",
        "            # args_dict['hub_strategy'] = \"epoch\" # Загружать в конце каждой эпохи (потребует соответствующей save_strategy)\n",
        "            # args_dict['hub_strategy'] = \"end\" # Загружать только в самом конце обучения\n",
        "            # Если hub_strategy не указан, поведение по умолчанию обычно \"end\" или синхронизировано с save_strategy.\n",
        "            # Для старых версий, где эти опции могут не работать, поведение может быть только \"в конце\".\n",
        "        else:\n",
        "            print(\"Модель НЕ будет загружена на Hugging Face Hub (hub_model_id не указан).\")\n",
        "\n",
        "        training_args = TrainingArguments(**args_dict)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            compute_metrics=self._compute_metrics\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            print(f\"Начало обучения... Чекпоинты будут сохраняться в: {self.checkpoints_path}\")\n",
        "            trainer.train()\n",
        "\n",
        "            # Сохраняем финальную модель локально в отдельную директорию (если нужно)\n",
        "            # или можно положиться на последний чекпоинт в self.checkpoints_path\n",
        "            final_model_path = Path(self.checkpoints_path) / \"final_model_after_training\"\n",
        "            trainer.save_model(str(final_model_path))\n",
        "            print(f\"Обучение завершено. Финальная модель сохранена локально в {final_model_path}\")\n",
        "\n",
        "            # Ручная загрузка на Hub (если push_to_hub в TrainingArguments не сработал или вы хотите сделать это явно)\n",
        "            if self.hub_model_id and not training_args.push_to_hub:\n",
        "                print(f\"Попытка загрузить модель на Hub вручную: {self.hub_model_id}\")\n",
        "                try:\n",
        "                    # trainer.push_to_hub() # обычно загружает все, включая токенизатор из args\n",
        "                    # или более явно:\n",
        "                    self.tokenizer.push_to_hub(self.hub_model_id, commit_message=\"Push tokenizer after training\")\n",
        "                    self.model.push_to_hub(self.hub_model_id, commit_message=\"Push model after training\")\n",
        "                    print(f\"Модель и токенизатор должны быть загружены на {self.hub_model_id}\")\n",
        "                except Exception as e_push:\n",
        "                    print(f\"Ошибка при ручной загрузке на Hub: {e_push}\")\n",
        "\n",
        "        except Exception as ex:\n",
        "            print(f'Ошибка во время обучения или сохранения/загрузки модели: {ex}')\n",
        "            raise\n",
        "\n",
        "    def _compute_metrics(self, eval_pred: EvalPrediction) -> Dict[str, float]:\n",
        "        \"\"\" Вычисление метрик.\n",
        "        Назначение:\n",
        "          Вычисляет метрики качества модели на основе предсказаний и истинных меток. Эта функция передается в Trainer.\n",
        "        Действия:\n",
        "          - Извлекает predictions (логиты) и labels (истинные метки).\n",
        "          - Применяет np.argmax к логитам вдоль оси классов (axis=1) для получения предсказанных классов (ID с наибольшей вероятностью).\n",
        "          - Вычисляет точность (accuracy) как долю совпадений между предсказанными и истинными метками.\n",
        "          - Возвращает словарь с метрикой, например, {'accuracy': 0.95}.\n",
        "        Args:\n",
        "          eval_pred (EvalPrediction): Объект, содержащий predictions (логиты модели, т.е. сырые выходы до применения softmax) и label_ids (истинные метки).\n",
        "        Returns:\n",
        "          Dict[str, float]: Словарь с метрикой качества.\n",
        "        \"\"\"\n",
        "        predictions_logits: np.ndarray = eval_pred.predictions\n",
        "        labels: np.ndarray = eval_pred.label_ids\n",
        "        predictions: np.ndarray = np.argmax(predictions_logits, axis=1)\n",
        "        accuracy: float | np.float_ = np.mean(predictions == labels)\n",
        "        return {'accuracy': accuracy}\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vwlS-CgGSLiI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    HF_MODEL_ID: Optional[str] = None\n",
        "    try:\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "        if not hf_token:\n",
        "            print(\"Токен HF_TOKEN не найден в секретах.\")\n",
        "        else:\n",
        "            print(\"Токен HF получен.\")\n",
        "            login(token=hf_token)\n",
        "            print(\"Успешная авторизация на HF Hub.\")\n",
        "            HF_MODEL_ID = \"hypo69/my_model_from_existing_datasets\" # <--- ИМЯ МОДЕЛИ\n",
        "    except userdata.SecretNotFoundError:\n",
        "        print(\"Секрет HF_TOKEN не найден.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при авторизации на HF Hub: {e}\")\n",
        "        HF_MODEL_ID = None\n",
        "\n",
        "\n",
        "    if 'checkpoints_path' not in locals() and 'checkpoints_path' not in globals():\n",
        "        checkpoints_path: str = \"./my_final_checkpoints\"\n",
        "        print(f\"Переменная 'checkpoints_path' не найдена, используется значение по умолчанию: {checkpoints_path}\")\n",
        "\n",
        "\n",
        "    # -------------------------------- labels_dict -----------------\n",
        "    if labels_dict:\n",
        "        calculated_num_labels_main = len(labels_dict)\n",
        "        # Опциональные проверки для labels_dict\n",
        "        if not all(isinstance(v, int) for v in labels_dict.values()):\n",
        "            print(\"Предупреждение: Не все значения в labels_dict являются целыми числами.\")\n",
        "        if not all(isinstance(k, str) for k in labels_dict.keys()):\n",
        "            print(\"Предупреждение: Не все ключи в labels_dict являются строками.\")\n",
        "    else:\n",
        "        labels_dict = {} # Гарантия, что это пустой словарь, а не None\n",
        "        print(\"Предупреждение: labels_dict пуст или не был загружен. num_labels будет 0.\")\n",
        "\n",
        "    if calculated_num_labels_main == 0:\n",
        "        print(\"Критическая ошибка: Количество меток (num_labels) равно 0.\")\n",
        "        # exit()\n",
        "    else:\n",
        "        print(f\"Итоговое количество меток (num_labels) для модели: {calculated_num_labels_main}\")\n",
        "\n",
        "\n",
        "    pipeline_instance: Optional[TextClassificationPipeline] = None\n",
        "    dataset_dict_for_pipeline_main: Optional[DatasetDict] = None\n",
        "    prepared_tokenized_datasets: Optional[Tuple[Dataset, Dataset] | Tuple[None, None]] = None\n",
        "    final_tokenized_train_data: Optional[Dataset] = None\n",
        "    final_tokenized_eval_data: Optional[Dataset] = None\n",
        "\n",
        "    try:\n",
        "        # Проверка, существуют ли train_dataset и eval_dataset\n",
        "        if ('train_dataset' not in locals() and 'train_dataset' not in globals()) or \\\n",
        "           ('eval_dataset' not in locals() and 'eval_dataset' not in globals()):\n",
        "            raise NameError(\"Переменные 'train_dataset' и/или 'eval_dataset' не определены. \"\n",
        "                            \"Убедитесь, что они созданы в предыдущих ячейках.\")\n",
        "\n",
        "        # Проверка, что они не None (на случай, если они были объявлены, но не инициализированы)\n",
        "        if train_dataset is None or eval_dataset is None:\n",
        "             raise ValueError(\"'train_dataset' или 'eval_dataset' являются None. \"\n",
        "                              \"Убедитесь, что они корректно созданы.\")\n",
        "\n",
        "        print(f\"Используется существующий train_dataset ({len(train_dataset)} записей) \"\n",
        "              f\"и eval_dataset ({len(eval_dataset)} записей).\")\n",
        "\n",
        "        # Проверка наличия колонок 'text' и 'labels' в существующих датасетах\n",
        "        for ds_name, ds_object in [(\"train_dataset\", train_dataset), (\"eval_dataset\", eval_dataset)]:\n",
        "            if ds_object: # Проверка, что объект не None\n",
        "                if 'text' not in ds_object.column_names or 'labels' not in ds_object.column_names:\n",
        "                    raise ValueError(f\"{ds_name} должен содержать колонки 'text' и 'labels'. \"\n",
        "                                     f\"Текущие колонки: {ds_object.column_names}\")\n",
        "                # Проверка, что все метки в данных находятся в диапазоне [0, num_labels-1]\n",
        "                # Эта проверка важна, так как `num_labels` берется из `labels_dict`\n",
        "                if calculated_num_labels_main > 0: # Только если у нас есть ожидаемое кол-во меток\n",
        "                    all_labels_in_ds = set(ds_object['labels'])\n",
        "                    if all_labels_in_ds and \\\n",
        "                       (max(all_labels_in_ds) >= calculated_num_labels_main or min(all_labels_in_ds) < 0):\n",
        "                        raise ValueError(\n",
        "                            f\"Метки в {ds_name} (диапазон: {min(all_labels_in_ds)}-{max(all_labels_in_ds)}) \"\n",
        "                            f\"выходят за пределы ожидаемого диапазона [0, {calculated_num_labels_main-1}], \"\n",
        "                            f\"определенного из actual_labels_dict. Уникальные метки: {sorted(list(all_labels_in_ds))}\"\n",
        "                        )\n",
        "                elif calculated_num_labels_main == 0 and ds_object['labels']: # Если actual_labels_dict пуст, но в данных есть метки\n",
        "                    print(f\"Предупреждение: actual_labels_dict пуст, но {ds_name} содержит метки. num_labels будет 0, что вызовет ошибку.\")\n",
        "\n",
        "\n",
        "        if calculated_num_labels_main > 0: # Продолжаем только если num_labels определен\n",
        "            dataset_dict_for_pipeline_main = DatasetDict({\n",
        "                'train': train_dataset,\n",
        "                'test': eval_dataset\n",
        "            })\n",
        "\n",
        "            pipeline_instance = TextClassificationPipeline(\n",
        "                num_labels=calculated_num_labels_main,\n",
        "                hub_model_id=HF_MODEL_ID,\n",
        "                checkpoints_path=checkpoints_path,\n",
        "                labels_map_dict= labels_dict\n",
        "            )\n",
        "        else:\n",
        "            print(\"Обучение не будет запущено, так как calculated_num_labels_main равен 0 (проблема с actual_labels_dict).\")\n",
        "\n",
        "        if pipeline_instance and dataset_dict_for_pipeline_main:\n",
        "            prepared_tokenized_datasets = pipeline_instance.prepare_datasets(dataset_dict_for_pipeline_main)\n",
        "\n",
        "            if prepared_tokenized_datasets and prepared_tokenized_datasets[0] and prepared_tokenized_datasets[1]:\n",
        "                final_tokenized_train_data, final_tokenized_eval_data = prepared_tokenized_datasets\n",
        "                print('Данные успешно токенизированы:')\n",
        "                print(f'Train: {len(final_tokenized_train_data)} п., Колонки: {final_tokenized_train_data.column_names}')\n",
        "                print(f'Eval: {len(final_tokenized_eval_data)} п., Колонки: {final_tokenized_eval_data.column_names}')\n",
        "\n",
        "                pipeline_instance.train(final_tokenized_train_data, final_tokenized_eval_data)\n",
        "            else:\n",
        "                print('Ошибка токенизации. Обучение не будет запущено.')\n",
        "        elif not pipeline_instance and calculated_num_labels_main > 0:\n",
        "             print(\"Пайплайн не был инициализирован.\")\n",
        "\n",
        "\n",
        "    except NameError as ne: # Если train_dataset или eval_dataset не существуют\n",
        "        print(f\"Ошибка NameError: {ne}\")\n",
        "        print(\"Убедитесь, что переменные train_dataset, eval_dataset и labels_dict (если не загружается здесь) определены в предыдущих ячейках.\")\n",
        "    except ValueError as ex:\n",
        "        print(f'Критическая ошибка (ValueError): {str(ex)}')\n",
        "    except Exception as ex:\n",
        "        import traceback\n",
        "        print(f'Непредвиденная ошибка: {str(ex)}')\n",
        "        print(\"Трассировка:\")\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "4da8338bf3544c78a6ba6561039a42e6",
            "9134b6ab1645405fa994d8ab7be961aa",
            "d5b211252ddd422a974c1c72ddd8e08c",
            "13a0bab6e46d440f98a01ee41dc34e9a",
            "b28de0a49d8948ceb2724c3e7d1cea4c",
            "03eb9005ec29421fae7e6c6d6c71d280",
            "5f35032986ce4d6aab6a5430e87b26b6",
            "677fdb776c8e40b2b6e6a67a147ff9a3",
            "482b5744a97a419f8381603103a76a7f",
            "91249c13550e42d7913762fda5bf3ef1",
            "39eaf7260870462e936b029ba4763a9d",
            "ae76af1e4bd94d9e9a7ed2523aa84e89",
            "ccd60145d59a488ea2d6e44b6ba74ba9",
            "d2faf42a13eb4c3c8ca720a9a8bfecd4",
            "880ff79dfe944b0da1c1e9adb7a8dca2",
            "cd041296557d4b69a98ad176c1a1a3e9",
            "57dcfac618184752b0e8f5e5ddb37426",
            "af1a4fee2f004131839a560fd0c8244c",
            "26386406f3304d51951f23d681c0c5f1",
            "651edc8ba5524ec89de845105c8dd544",
            "2f7272d36afa42f090e53b73a7f397b2",
            "0bc6de97f35e4e9a9dcc5a9eabc076b6"
          ]
        },
        "id": "KcXNOQZljL0t",
        "outputId": "7879318c-cb12-4d5b-ede0-983c9dbb74be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Токен HF получен.\n",
            "Успешная авторизация на HF Hub.\n",
            "Итоговое количество меток (num_labels) для модели: 37\n",
            "Используется существующий train_dataset (41 записей) и eval_dataset (11 записей).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начало токенизации для датасетов: ['train', 'test']...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da8338bf3544c78a6ba6561039a42e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Токенизация с max_length=512, stride=256 (stride_ratio=0.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae76af1e4bd94d9e9a7ed2523aa84e89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Токенизация с max_length=512, stride=256 (stride_ratio=0.5)\n",
            "Токенизация датасетов завершена.\n",
            "Данные успешно токенизированы:\n",
            "Train: 672 п., Колонки: ['labels', 'input_ids', 'attention_mask']\n",
            "Eval: 177 п., Колонки: ['labels', 'input_ids', 'attention_mask']\n",
            "Рассчитанное количество шагов на эпоху: 84\n",
            "Модель будет загружена на Hugging Face Hub как: hypo69/my_model_from_existing_datasets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-18-dbb5732824e9>:201: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начало обучения... Чекпоинты будут сохраняться в: /content/drive/MyDrive/hypo69/llm/checkpoints\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 24/252 10:48 < 1:51:58, 0.03 it/s, Epoch 0.27/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.641900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBcb6SQVW27V"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EWjetUEEQzPP"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4da8338bf3544c78a6ba6561039a42e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9134b6ab1645405fa994d8ab7be961aa",
              "IPY_MODEL_d5b211252ddd422a974c1c72ddd8e08c",
              "IPY_MODEL_13a0bab6e46d440f98a01ee41dc34e9a"
            ],
            "layout": "IPY_MODEL_b28de0a49d8948ceb2724c3e7d1cea4c"
          }
        },
        "9134b6ab1645405fa994d8ab7be961aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03eb9005ec29421fae7e6c6d6c71d280",
            "placeholder": "​",
            "style": "IPY_MODEL_5f35032986ce4d6aab6a5430e87b26b6",
            "value": "Map: 100%"
          }
        },
        "d5b211252ddd422a974c1c72ddd8e08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677fdb776c8e40b2b6e6a67a147ff9a3",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_482b5744a97a419f8381603103a76a7f",
            "value": 41
          }
        },
        "13a0bab6e46d440f98a01ee41dc34e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91249c13550e42d7913762fda5bf3ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_39eaf7260870462e936b029ba4763a9d",
            "value": " 41/41 [00:00&lt;00:00, 54.34 examples/s]"
          }
        },
        "b28de0a49d8948ceb2724c3e7d1cea4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03eb9005ec29421fae7e6c6d6c71d280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f35032986ce4d6aab6a5430e87b26b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "677fdb776c8e40b2b6e6a67a147ff9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482b5744a97a419f8381603103a76a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91249c13550e42d7913762fda5bf3ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39eaf7260870462e936b029ba4763a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae76af1e4bd94d9e9a7ed2523aa84e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd60145d59a488ea2d6e44b6ba74ba9",
              "IPY_MODEL_d2faf42a13eb4c3c8ca720a9a8bfecd4",
              "IPY_MODEL_880ff79dfe944b0da1c1e9adb7a8dca2"
            ],
            "layout": "IPY_MODEL_cd041296557d4b69a98ad176c1a1a3e9"
          }
        },
        "ccd60145d59a488ea2d6e44b6ba74ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57dcfac618184752b0e8f5e5ddb37426",
            "placeholder": "​",
            "style": "IPY_MODEL_af1a4fee2f004131839a560fd0c8244c",
            "value": "Map: 100%"
          }
        },
        "d2faf42a13eb4c3c8ca720a9a8bfecd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26386406f3304d51951f23d681c0c5f1",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_651edc8ba5524ec89de845105c8dd544",
            "value": 11
          }
        },
        "880ff79dfe944b0da1c1e9adb7a8dca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7272d36afa42f090e53b73a7f397b2",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc6de97f35e4e9a9dcc5a9eabc076b6",
            "value": " 11/11 [00:00&lt;00:00, 52.87 examples/s]"
          }
        },
        "cd041296557d4b69a98ad176c1a1a3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57dcfac618184752b0e8f5e5ddb37426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1a4fee2f004131839a560fd0c8244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26386406f3304d51951f23d681c0c5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651edc8ba5524ec89de845105c8dd544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f7272d36afa42f090e53b73a7f397b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc6de97f35e4e9a9dcc5a9eabc076b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}