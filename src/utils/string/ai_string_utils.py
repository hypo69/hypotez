# -*- coding: utf-8 -*-
#! .pyenv/bin/python3

"""
Утилиты для приведения строк к требованиям обучения и нормализации ответов от языковых моделей.
================================================================================================

**Назначение**

Этот модуль предоставляет функции для обработки и очистки строк, включая:
1.  Подготовку текстовых данных для обучающих наборов (экранирование кавычек, удаление лишних пробелов).
2.  Нормализацию ответов от языковых моделей (удаление обрамляющих блоков кода).

.. module:: src.utils.string.combined_string_utils  # Пример нового пути модуля
"""

import re
from typing import Union, List

# =========================================================================================
# Функции для подготовки данных для обучения (из string_for_train.py)
# =========================================================================================

def string_for_train(data: Union[str, List[str]]) -> str:
    """
    Очищает и форматирует данные для обучения. Удаляет повторяющиеся пробелы.

    Экранирует двойные кавычки (`"`) символом обратной косой черты (`\\`)
    и заменяет множественные пробельные символы одним пробелом.
    Удаляет начальные и конечные пробелы.

    Args:
        data (Union[str, List[str]]): Входные данные. Могут быть строкой или
                                      списком строк.

    Returns:
        str: Очищенная и объединенная строка (если на входе был список),
             готовая для использования в обучении. Возвращает пустую строку,
             если тип входных данных не строка и не список строк.

    Examples:
        >>> string_for_train('   Это  строка   с "кавычками"   и    пробелами. ')
        'Это строка с \\"кавычками\\" и пробелами.'
        >>> string_for_train(['Первая строка.', '   Вторая "строка"   с пробелами.'])
        'Первая строка. Вторая \\"строка\\" с пробелами.'
        >>> string_for_train(None)
        ''
        >>> string_for_train(123)
        ''
    """
    cleaned_text: str = ""

    if isinstance(data, str):
        # Экранирование кавычек и очистка от `\n`
        cleaned_text = data.replace('"', '\\"').replace('\n','')
        # Удаление повторяющихся пробелов и обрезка краев
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text
    elif isinstance(data, list):
        # Обработка каждого элемента списка
        processed_items = []
        for item in data:
            if isinstance(item, str):
                # Экранирование кавычек
                cleaned_item = item.replace('"', '\\"').replace('\n','')
                # Нормализация пробелов (но не объединение через re.sub пока)
                processed_items.append(cleaned_item)
            else:
                # Пропустить нестроковые элементы или обработать иначе?
                # В текущей реализации они будут проигнорированы при объединении,
                # но можно добавить логирование или обработку ошибок.
                ...
        # Объединение элементов списка в одну строку через пробел
        cleaned_text = ' '.join(processed_items)
        # Финальное удаление повторяющихся пробелов и обрезка краев всей строки
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text
    else:
        # Возврат пустой строки для некорректного типа данных
        return ""

# =========================================================================================
# Функции для нормализации ответов ИИ (из ai_response_normalizer.py)
# =========================================================================================

# Список префиксов и суффиксов, обозначающих блоки кода в ответах моделей
_NORMALIZER_PREFIXES: list[str] = [
    '```md\n',
    '```md ', # Добавим вариант с пробелом
    '```md',
    '```markdown\n',
    '```markdown ', # Добавим вариант с пробелом
    '```markdown',
    '```html\n',
    '```html ', # Добавим вариант с пробелом
    '```html',
    '```json\n', # Добавим другие возможные типы
    '```json ',
    '```json',
    '```python\n',
    '```python ',
    '```python',
    '```text\n',
    '```text ',
    '```text',
    '```\n',
    '``` ',
    '```',
]
_NORMALIZER_SUFFIX: str = '```'


def normalize_answer(text: str) -> str:
    """
    Нормализует текстовый ответ, удаляя обрамляющие блоки кода markdown.

    Проверяет, начинается ли строка `text` одним из префиксов из списка
    `_NORMALIZER_PREFIXES` (например, '```html\\n', '```markdown', '```')
    и заканчивается ли она суффиксом `_NORMALIZER_SUFFIX` ('```').
    Если оба условия выполняются, удаляет соответствующий префикс и суффикс.
    В противном случае возвращает исходную строку без изменений.

    Args:
        text (str): Исходная строка текста, потенциально содержащая
                    обрамляющие блоки кода.

    Returns:
        str: Нормализованная строка без начального и конечного блоков кода,
             либо исходная строка, если блоки не найдены.

    Examples:
        >>> normalize_answer("```html\\n<p>Пример</p>\\n```")
        '<p>Пример</p>\\n'
        >>> normalize_answer("```markdown\n# Заголовок\nТекст.\n```")
        '# Заголовок\\nТекст.\\n'
        >>> normalize_answer("```\nПросто текст\n```")
        'Просто текст\\n'
        >>> normalize_answer("Обычный текст без блоков.")
        'Обычный текст без блоков.'
        >>> normalize_answer("```Неполный блок")
        '```Неполный блок'
        >>> normalize_answer("Блок в конце```")
        'Блок в конце```'
        >>> normalize_answer("```md Текст```") # Пример с пробелом после md
        'Текст'
    """
    if not isinstance(text, str):
        # Можно добавить обработку ошибок или вернуть пустую строку/None
        return "" # Или return text, если нужно пропустить не-строки

    normalized_text = text # Начинаем с исходного текста

    for prefix in _NORMALIZER_PREFIXES:
        # Проверяем наличие префикса И суффикса
        if normalized_text.startswith(prefix) and normalized_text.endswith(_NORMALIZER_SUFFIX):
            # Удаляем префикс
            normalized_text = normalized_text.removeprefix(prefix)
            # Удаляем суффикс
            normalized_text = normalized_text.removesuffix(_NORMALIZER_SUFFIX)
            # Так как нашли и удалили, можно выходить из цикла
            break # Важно: прекращаем поиск после первого совпадения

    # Можно добавить .strip() для удаления случайных пробелов по краям после удаления блоков
    # return normalized_text.strip()
    return normalized_text

# =========================================================================================
# Пример использования (можно закомментировать или удалить)
# =========================================================================================
if __name__ == '__main__':
    # Примеры для string_for_train
    print("--- string_for_train ---")
    test_str = '   Это  строка   с "кавычками"   и    пробелами. '
    print(f"Original: '{test_str}'")
    print(f"Cleaned:  '{string_for_train(test_str)}'")

    test_list = ['Первая строка.', '   Вторая "строка"   с пробелами.', ' Третья    ', '   ']
    print(f"Original list: {test_list}")
    print(f"Cleaned list: '{string_for_train(test_list)}'")

    print(f"Invalid input (int): '{string_for_train(123)}'")
    print(f"Invalid input (None): '{string_for_train(None)}'")


    # Примеры для normalize_answer
    print("\n--- normalize_answer ---")
    tests_norm = [
        "```html\n<p>Пример</p>\n```",
        "```markdown\n# Заголовок\nТекст.\n```",
        "```\nПросто текст\n```",
        "Обычный текст без блоков.",
        "```Неполный блок",
        "Блок в конце```",
        "```json\n{\"key\": \"value\"}\n```",
        "```md Текст```"
    ]
    for test_case in tests_norm:
        print(f"Original: '{test_case}'")
        print(f"Normalized: '{normalize_answer(test_case)}'")

    print(f"Invalid input (int): '{normalize_answer(123)}'") # type: ignore